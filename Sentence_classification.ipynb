{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentence_classification",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1OXwZP8YCMdLnZn4FrdGcTHJCbQsrauIE",
      "authorship_tag": "ABX9TyOIbALanZe2qVBcObLcq+rf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gituhin/Sentence-Classification-naive-bayes-/blob/main/Sentence_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uU0Vu_9TYvhl"
      },
      "source": [
        "importing necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rc8uOsXUqDM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59a59b12-4adc-4c15-a7d5-040586e7e12f"
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "import string \n",
        "import gspread\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-URNDnvnKgK"
      },
      "source": [
        "loading the train dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVPiVB2PjOhV"
      },
      "source": [
        "gc = gspread.authorize(GoogleCredentials.get_application_default())\n",
        "worksheet = gc.open('traindata').sheet1\n",
        "rows = worksheet.get_all_values()\n",
        "# Convert to a DataFrame and render.\n",
        "data=pd.DataFrame.from_records(rows)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHxFcJOMIWTZ"
      },
      "source": [
        "Line preprocessing function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrH0R7xbjlX5"
      },
      "source": [
        "def preprocessline(data, c):\n",
        "  step=str.maketrans('','',string.punctuation)    #removing punctuations\n",
        "  line=data[1][c].translate(step) \n",
        "  line=line.lower()       #converting all words to lower cases and splitting them\n",
        "  words=line.split()\n",
        "\n",
        "  st_words=stopwords.words('english')\n",
        "  i=0\n",
        "  while i<len(words):\n",
        "    if words[i] in st_words:     #removing the stop words, finding them and poping them out from the words splitted list\n",
        "      words.pop(i)\n",
        "      i=0\n",
        "    i+=1\n",
        "  return words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pW2GLq0IIkrc"
      },
      "source": [
        "Storing unique words in each category in corresponding sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSaYIGhWdVbm"
      },
      "source": [
        "word_set=set()\n",
        "for c in range(1, len(data)):           #unique collections of words in a set to avoid repetitions\n",
        "  word_set.update(preprocessline(data, c))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0weTG08dA8x"
      },
      "source": [
        "science=set()                 \n",
        "covid=set()                       #set of words in each category which would be used as reference for creating vocabulary\n",
        "business=set()\n",
        "sports=set()\n",
        "st_words=stopwords.words('english')\n",
        "\n",
        "for labels in range(1, len(data)):\n",
        "  if data[0][labels]=='science':\n",
        "    words=preprocessline(data, labels)\n",
        "    science.update(words)\n",
        "\n",
        "  \n",
        "  elif data[0][labels]=='covid':\n",
        "    words=preprocessline(data, labels)\n",
        "    covid.update(words) \n",
        "  \n",
        "  elif data[0][labels]=='business':\n",
        "    words=preprocessline(data, labels)\n",
        "    business.update(words)\n",
        "  \n",
        "  else:\n",
        "    words=preprocessline(data, labels)\n",
        "    sports.update(words)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhyb60ossEWP"
      },
      "source": [
        "Creating Vocabulary with frequencies of words in a class.\r\n",
        "*classes are viz:* \r\n",
        "\r\n",
        "*   science\r\n",
        "*   covid\r\n",
        "\r\n",
        "*   business\r\n",
        "*   sports\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDOmz3sTTMoi"
      },
      "source": [
        "words_in_science={}\n",
        "words_in_covid={}\n",
        "words_in_business={}          #dictionaries used for each category, the key stores the words and the corresponding values store the frequency\n",
        "words_in_sports={}\n",
        "\n",
        "for p in science:\n",
        "  words_in_science[p]=0\n",
        "for p in business:\n",
        "  words_in_business[p]=0        #initially setting frequencies of all words=0\n",
        "for p in covid:\n",
        "  words_in_covid[p]=0\n",
        "for p in sports:\n",
        "  words_in_sports[p]=0\n",
        "\n",
        "\n",
        "for labels in range(1, len(data)):\n",
        "  if data[0][labels]=='science':\n",
        "    words=preprocessline(data, labels)          #iterating the frequencies of the words in different categories\n",
        "    for wd in words:\n",
        "      words_in_science[wd]+=1\n",
        "\n",
        "  elif data[0][labels]=='business':\n",
        "    words=preprocessline(data, labels)\n",
        "    for wd in words:\n",
        "      words_in_business[wd]+=1\n",
        "\n",
        "\n",
        "  elif data[0][labels]=='covid':\n",
        "    words=preprocessline(data, labels)\n",
        "    for wd in words:\n",
        "      words_in_covid[wd]+=1\n",
        "\n",
        "  else:\n",
        "    words=preprocessline(data, labels)\n",
        "    for wd in words:\n",
        "      words_in_sports[wd]+=1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kb6Hhbw6IPbh"
      },
      "source": [
        "Calculating Prior distributions of classes\r\n",
        "[no. of times the class occurs/total no. of classes]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akg2qdlHEOaJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6bc3f31-ccb9-44a5-ff97-027b5cbebee0"
      },
      "source": [
        "class_labels=set()\n",
        "for label in range(1, len(data)):\n",
        "  class_labels.add(data[0][label])\n",
        "category={}\n",
        "\n",
        "for label in class_labels:\n",
        "  freq=0\n",
        "  for i in range(1, len(data)):\n",
        "   if label==data[0][i]:\n",
        "    freq+=1\n",
        "  category[label]=freq\n",
        "\n",
        "print('the prior distributions of classes are:')\n",
        "p_business=category['business']/(len(data)-1)\n",
        "p_science=category['science']/(len(data)-1)\n",
        "p_sports=category['sports']/(len(data)-1)\n",
        "p_covid=category['covid']/(len(data)-1)\n",
        "\n",
        "print(\"business=\",p_business)\n",
        "print(\"covid=\", p_covid )\n",
        "print(\"science=\", p_science )\n",
        "print(\"sports=\", p_sports )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the prior distributions of classes are:\n",
            "business= 0.2375\n",
            "covid= 0.2625\n",
            "science= 0.25\n",
            "sports= 0.25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsCtTqTez2TE"
      },
      "source": [
        "# Class conditional probability of each word in document\r\n",
        "\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "no. of time the word occurs in a particular class/total no. of words in that class\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7ULrhZZtud0"
      },
      "source": [
        "total_science, total_covid, total_business, total_sports=0,0,0,0\n",
        "\n",
        "for t in words_in_business:\n",
        "  total_business+=words_in_business[t]\n",
        "for t in words_in_science:                      #summing up the total number of words in each categories for total no. of words in a class\n",
        "  total_science+=words_in_science[t]\n",
        "for t in words_in_covid:\n",
        "  total_covid+=words_in_covid[t]\n",
        "for t in words_in_sports:\n",
        "  total_sports+=words_in_sports[t]\n",
        "\n",
        "prob_science={}\n",
        "prob_covid={}\n",
        "prob_business={}          #dictionaries used for storing the class conditional probailities of words\n",
        "prob_sports={}\n",
        "\n",
        "for a in words_in_business:\n",
        "  prob_business[a]=words_in_business[a]/total_business\n",
        "for a in words_in_science:\n",
        "  prob_science[a]=words_in_science[a]/total_science\n",
        "for a in words_in_covid:\n",
        "  prob_covid[a]=words_in_covid[a]/total_covid\n",
        "for a in words_in_sports:\n",
        "  prob_sports[a]=words_in_sports[a]/total_sports\n",
        "\n",
        "for wdr in word_set:\n",
        "  if wdr not in science:\n",
        "    prob_science[wdr]=0.00001\n",
        "  if wdr not in sports:                   #if the words is not in the sentence then assigning it a small probability almost near 0, but should not be 0\n",
        "    prob_sports[wdr]=0.00001\n",
        "  if wdr not in covid:\n",
        "    prob_covid[wdr]=0.00001\n",
        "  if wdr not in business:\n",
        "    prob_business[wdr]=0.00001\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cY2A7Vv_WXbq"
      },
      "source": [
        "Applying the trained model in test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q96VLkBaV1O0"
      },
      "source": [
        "worksheet1= gc.open('testdata').sheet1\n",
        "rows = worksheet1.get_all_values()\n",
        "test_data=pd.DataFrame.from_records(rows)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZohUD1Hq52Ws"
      },
      "source": [
        "# Calculating posterier distribution of given sentences over classes\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "by Naive Bayes formula we calculate the posterior distribution of each sentence\r\n",
        "belonging to a particular class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiUffsEtgI5d"
      },
      "source": [
        "for c in range(1, len(test_data)):\n",
        "  words1=preprocessline(test_data, c)\n",
        "\n",
        "  for wds in words1:\n",
        "    if wds not in word_set:\n",
        "      prob_business[wds]=0.00001\n",
        "      prob_science[wds]=0.00001\n",
        "      prob_covid[wds]=0.00001                   #if the word in testset not in trainset then assigning a small probabilty \n",
        "      prob_sports[wds]=0.00001\n",
        "\n",
        "  postp_science=1\n",
        "  postp_business=1\n",
        "  postp_covid=1\n",
        "  postp_sports=1\n",
        "\n",
        "  for wds in words1:\n",
        "    postp_science*=prob_science[wds]\n",
        "    postp_business*=prob_business[wds]\n",
        "    postp_covid*=prob_covid[wds]\n",
        "    postp_sports*=prob_sports[wds]\n",
        "\n",
        "  postp_science=postp_science*p_science/(1.00e-20)\n",
        "  postp_covid=postp_covid*p_covid/(1.00e-20)                          #here the denominator/the probabilty of given sentence is same for all hence 1.00e-20 has been\n",
        "  postp_business=postp_business*p_business/(1.00e-20)             #choosen as an appropiate upscaling factor since all are affected by same factor.\n",
        "  postp_sports=postp_sports*p_sports/(1.00e-20)\n",
        "  print('the probability of sentence %d being science is '%c, postp_science)\n",
        "  print('the probability of sentence %d being covid is '%c, postp_covid)\n",
        "  print('the probability of sentence %d being business is '%c, postp_business)\n",
        "  print('the probability of sentence %d being sports is '%c, postp_sports)\n",
        "  print('\\n')\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NihsZz2CjSfe"
      },
      "source": [
        "I have winded up till posterior distribution, next we can select the class having the max. probabilty. All the predicted results do match the test categories."
      ]
    }
  ]
}